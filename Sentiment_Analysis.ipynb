{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-XqZZCjlNIZ"
      },
      "source": [
        "#SENTIMENT ANALYSIS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOCF9tKlIspw"
      },
      "source": [
        "##1.Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmuEZmB47rmN"
      },
      "outputs": [],
      "source": [
        "# Tập dữ liệu ví dụ\n",
        "\n",
        "train_x = [\n",
        "           'just plain boring',\n",
        "           'entirely predictable and lacks energy',\n",
        "           'no surprises and very few laughs',\n",
        "           'very powerful',\n",
        "           'the most fun film of the summer'\n",
        "]\n",
        "train_y = [0, 0, 0, 1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZp30Q5ZJBSr"
      },
      "source": [
        "###1.1. Tiền xử lý dữ liệu cơ bản"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4_6pcOfI_TN",
        "outputId": "72587b21-90f9-4670-c312-4c3d5c178eef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['just', 'plain', 'boring']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "def basic_preprocess(text):\n",
        "    \"\"\" Tiền xử lý và tách các câu\n",
        "    Args:\n",
        "        text: câu đầu vào. \n",
        "        VD: \"Tôi đi học\"\n",
        "    Output:\n",
        "        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n",
        "            được phân tách bởi khoảng trắng\n",
        "    \"\"\"\n",
        "    text_clean = text.lower()\n",
        "    return text_clean.split()\n",
        "\n",
        "basic_preprocess(train_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoUOaYc3KFg4"
      },
      "source": [
        "###1.2.Xây dựng bộ từ điển"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7JXmmbjKDp1"
      },
      "outputs": [],
      "source": [
        "# Ex 1\n",
        "def count_freq_words(corpus, labels):\n",
        "    \"\"\" Xây dựng bộ từ điển tần suất xuất hiện của các từ\n",
        "    Args:\n",
        "        corpus: tập danh sách các câu\n",
        "        labels: tập nhãn tương ứng với các câu trong corpus (0 hoặc 1)\n",
        "    Output:\n",
        "        model: bộ từ điển ánh xạ mỗi từ và tần suất xuất hiện của từ đó trong corpus\n",
        "            key: (word, label)\n",
        "            value: frequency\n",
        "            VD: {('boring', 0): 2} => từ boring xuất hiện 2 lần trong các sample thuộc class 0\n",
        "    \"\"\"\n",
        "    model = {}\n",
        "    for label, sentence in zip(labels, corpus):\n",
        "        for word in basic_preprocess(sentence):\n",
        "            # Định nghĩa key của model là tuple (word, label)\n",
        "            pair = (word, label)\n",
        "            # Nếu key đã tồn tại trong model thì tăng value lên 1\n",
        "            if pair in model:\n",
        "                model[pair] += 1\n",
        "            # Nếu key chưa tồn tại trong model thì bổ sung key vào model với value =1\n",
        "            else:\n",
        "                model[pair] = 1\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdDMOM-9MURU",
        "outputId": "09454016-0908-4b99-9475-7b2ecbd2ab45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('just', 0): 1,\n",
              " ('plain', 0): 1,\n",
              " ('boring', 0): 1,\n",
              " ('entirely', 0): 1,\n",
              " ('predictable', 0): 1,\n",
              " ('and', 0): 2,\n",
              " ('lacks', 0): 1,\n",
              " ('energy', 0): 1,\n",
              " ('no', 0): 1,\n",
              " ('surprises', 0): 1,\n",
              " ('very', 0): 1,\n",
              " ('few', 0): 1,\n",
              " ('laughs', 0): 1,\n",
              " ('very', 1): 1,\n",
              " ('powerful', 1): 1,\n",
              " ('the', 1): 2,\n",
              " ('most', 1): 1,\n",
              " ('fun', 1): 1,\n",
              " ('film', 1): 1,\n",
              " ('of', 1): 1,\n",
              " ('summer', 1): 1}"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "#Kết quả mong đợi\n",
        "freqs = count_freq_words(train_x, train_y)\n",
        "freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gw126f5pTqJ",
        "outputId": "754b8d25-0f91-4d19-883f-c9215e116098"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Hàm lấy ra tần suất xuất hiện là value trong `freq` dựa vào key (word, label)\n",
        "def lookup(freqs, word, label):\n",
        "    '''\n",
        "    Args:\n",
        "        freqs: a dictionary with the frequency of each pair\n",
        "        word: the word to look up\n",
        "        label: the label corresponding to the word\n",
        "    Output:\n",
        "        count: the number of times the word with its corresponding label appears.\n",
        "    '''\n",
        "    count = 0\n",
        "\n",
        "    pair = (word, label)\n",
        "    if pair in freqs:\n",
        "        count = freqs[pair]\n",
        "\n",
        "    return count\n",
        "\n",
        "lookup(freqs, \"just\", 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaSqdNkUNdiI"
      },
      "source": [
        "###1.3.Thuật toán phân loại Naive Bayes\n",
        "**Bước 1: Tính xác suất tiên nghiệm của các class**\n",
        "- Tính $D$, $D_{pos}$, $D_{neg}$\n",
        "    - Dựa vào `train_y` tính số lượng các sample có trong tập training: $D$, số lượng các sample là positive (nhãn 1): $D_{pos}$ và số lượng nhãn là negative (nhãn 0): $D_{neg}$\n",
        "    - Tính xác suất tiên nghiệm của class 1 là: $P(D_{pos})=D_{pos}/D$, và class 0 là: $P(D_{pos})=D_{pos}/D$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu4bNZthdi9R"
      },
      "outputs": [],
      "source": [
        "# Ex 2\n",
        "def compute_prior_prob(train_y):\n",
        "    # Tính D, D_pos, D_neg dựa vào x_train\n",
        "    # Tính D, số lượng các sample trong training\n",
        "    D = len(train_y)\n",
        "\n",
        "    # Tính D_pos, số lượng các positive sample trong training\n",
        "    D_pos = len(list(filter(lambda x: x == 1, train_y)))\n",
        "    print(D_pos)\n",
        "    # Tính D_neg, số lượng các negative sample trong training\n",
        "    D_neg = len(list(filter(lambda x: x == 0, train_y)))\n",
        "    print(D_neg)\n",
        "    # Tính xác suất tiên nghiệm cho các class 0 và 1\n",
        "    p_prior = {0:(D_neg/D), 1:(D_pos/D)}\n",
        "    return p_prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms7OTsAEf30f",
        "outputId": "5a95dcd1-dfe2-4242-b510-732d2c20072c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6, 1: 0.4}"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "# Kết quả mong đợi\n",
        "compute_prior_prob(train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cnux4rwgsNK"
      },
      "source": [
        "**Bước 2: Tính xác suất likelihood**\n",
        "- Tính $V$: Dựa vào `freqs` tính số lượng các từ duy nhất (uniqe words) - gọi là bộ từ điển\n",
        "\n",
        "- Tính $N_{pos}$ và $N_{neg}$: Dựa vào `freqs` dictionary, tính tổng số từ (có thể trùng lặp) xuất hiện trong positive samples $N_{pos}$ và negative samples $N_{neg}$.\n",
        "\n",
        "- Tính tần suất xuất hiện của mỗi từ trong positive samples $freq_{pos}$ và trong negative samples $freq_{neg}$\n",
        "\n",
        "- Tính xác suất likelihood mỗi từ trong bộ từ điển\n",
        "    - Sử dụng hàm `lookup` lấy ra tần suất xuất hiện của từ là positive $freq_{pos}$, và tần xuất xuất hiện của từ là negative $freq_{neg}$\n",
        "- Tính xác suất cho mỗi từ thuộc vào positive sample: $P(W_{pos})$, thuộc vào negative sample $P(W_{neg})$ sử dụng công thức 4 & 5.\n",
        "\n",
        "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
        "$$ P(W_{neg}) = \\frac{freq_{neg} + 1}{N_{neg} + V}\\tag{5} $$\n",
        "\n",
        "**Note:** Chúng ta lưu trữ likelihood của mỗi từ vào dictionary với key (từ): $W$, value (dictionary): ${0: P(W_{pos}), 1: P(W_{pos})}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKHq1sN-l_Oe"
      },
      "outputs": [],
      "source": [
        "# Ex 3\n",
        "def compute_likelihood(freqs):\n",
        "    # Tính xác suất likelihood của mỗi từ trong bộ từ điển\n",
        "\n",
        "    # Tính V các từ duy nhất xuất hiện trong tập train\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # Tính N_pos: số lượng từ trong positive samples và N_neg: số từ trong negative sample\n",
        "    N_pos = N_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # Nếu như class: 1 tăng N_pos thêm số lần xuất hiện của pair trong freqs\n",
        "        if pair[1] > 0:\n",
        "            N_pos += freqs[pair]\n",
        "\n",
        "        # Nếu như class: 0 tăng N_neg thêm số lần xuất hiện của pair trong freqs\n",
        "        else:\n",
        "            N_neg += freqs[pair]\n",
        "    \n",
        "    print(f'V: {V}, N_pos: {N_pos}, N_neg: {N_neg}')\n",
        "\n",
        "    # Tính likelihood cho mỗi từ trong bộ từ điển\n",
        "    p_likelihood = {}\n",
        "    for word in vocab:\n",
        "        # Lấy tần xuất xuất hiện của mỗi từ là positive hoặc negative\n",
        "        freq_pos = lookup(freqs, word, 1)\n",
        "        freq_neg = lookup(freqs, word, 0)\n",
        "\n",
        "        # Tính xác suất likelihood của mỗi từ với class positive và negative\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
        "\n",
        "        # Lưu vào p_likelihood dictionary\n",
        "        p_likelihood[word] = {0:p_w_neg, 1:p_w_pos}\n",
        "    \n",
        "    return p_likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qc94FJqog-G",
        "outputId": "0e5c91f9-a17b-4f6e-b7e0-fb634de812d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V: 20, N_pos: 9, N_neg: 14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'energy': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'fun': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'lacks': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'plain': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'of': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'boring': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'surprises': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'very': {0: 0.058823529411764705, 1: 0.06896551724137931},\n",
              " 'film': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'powerful': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'predictable': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'no': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'summer': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'just': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'and': {0: 0.08823529411764706, 1: 0.034482758620689655},\n",
              " 'entirely': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'few': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              " 'most': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              " 'the': {0: 0.029411764705882353, 1: 0.10344827586206896},\n",
              " 'laughs': {0: 0.058823529411764705, 1: 0.034482758620689655}}"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# Kết quả mong đợi\n",
        "compute_likelihood(freqs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzzrMkeQo_wu"
      },
      "source": [
        "**Bước 3: Hoàn thiện `train` function cho Naive Bayes***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2patcrx8Gfh"
      },
      "outputs": [],
      "source": [
        "def train_naive_bayes(train_x, train_y):\n",
        "    ''' Huấn luyện thuật toán Naive Bayes\n",
        "    Args:\n",
        "        train_x: Danh sách các câu\n",
        "        train_y: Danh sách các nhãn tương ứng (0 hoặc 1)\n",
        "    Output:\n",
        "        p_prior: the prior probability (Xác suấ tiên nghiệm)\n",
        "        p_likelihood: the maximum likelihood of the probability.\n",
        "    '''\n",
        "    # Xây dựng từ điển tần suất xuất hiện của từ và nhãn tương ứng\n",
        "    freqs = count_freq_words(train_x, train_y)\n",
        "\n",
        "    # Tính xác suất tiên nghiệm\n",
        "    p_prior = compute_prior_prob(train_y)\n",
        "\n",
        "    # Tính xác suất likelihood\n",
        "    p_likelihood = compute_likelihood(freqs)\n",
        "\n",
        "    return p_prior, p_likelihood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7739wp07pqa6",
        "outputId": "906a71e3-46c0-4da6-b187-f56e87b72d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "3\n",
            "V: 20, N_pos: 9, N_neg: 14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 0.6, 1: 0.4},\n",
              " {'energy': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'fun': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'lacks': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'plain': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'of': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'boring': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'surprises': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'very': {0: 0.058823529411764705, 1: 0.06896551724137931},\n",
              "  'film': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'powerful': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'predictable': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'no': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'summer': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'just': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'and': {0: 0.08823529411764706, 1: 0.034482758620689655},\n",
              "  'entirely': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'few': {0: 0.058823529411764705, 1: 0.034482758620689655},\n",
              "  'most': {0: 0.029411764705882353, 1: 0.06896551724137931},\n",
              "  'the': {0: 0.029411764705882353, 1: 0.10344827586206896},\n",
              "  'laughs': {0: 0.058823529411764705, 1: 0.034482758620689655}})"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "# Kết quả đầu ra thu được khi huấn luận Naive Bayes Classifier\n",
        "p_prior, p_likelihood = train_naive_bayes(train_x, train_y)\n",
        "p_prior, p_likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUmfzZwip2x3"
      },
      "source": [
        "###1.4.Dự đoán với các mẫu thử nghiệm\n",
        "- Tính xác suất của mỗi sample (n từ) dựa vào công thức:\n",
        "$$P(0).P(S|0) = P(0).P(w_{1}|0).P(w_{2}|0)...P(w_{n}|0)$$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LddVc6Zu_Q07"
      },
      "outputs": [],
      "source": [
        "# Ex 4\n",
        "def naive_bayes_predict(sentence, p_prior, p_likelihood):\n",
        "    '''\n",
        "    Args:\n",
        "        sentence: a string\n",
        "        p_prior: a dictionary of the prior probability\n",
        "        p_likelihood: a dictionary of words mapping to the probability\n",
        "    Output:\n",
        "        p: the probability of sentence with 0: negative, 1: positive\n",
        "\n",
        "    '''\n",
        "    # Tiền xử lý dữ liệu\n",
        "    words = basic_preprocess(sentence)\n",
        "\n",
        "    # Khởi tạo giá trị xác suất ban đầu là giá trị xác suất tiên nghiệm\n",
        "    p_neg = p_prior[0]\n",
        "    p_pos = p_prior[1]\n",
        "    \n",
        "    for word in words:\n",
        "        # Kiểm tra xem word có tồn tại trong p_likelihood hay không\n",
        "        if word in p_likelihood:\n",
        "            # nhân xác suất tiên nghiệm với xác suất likelihood của các từ\n",
        "            p_neg *= p_likelihood[word][0]\n",
        "            p_pos *= p_likelihood[word][1]\n",
        "   \n",
        "    return {'prob': {0: p_neg, 1: p_pos},\n",
        "            'label': 0 if p_neg > p_pos else 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd3X74kBAnrK",
        "outputId": "1d351a54-e191-4591-e311-2a1f244b713a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prob': {0: 6.106248727864848e-05, 1: 3.2801672885317154e-05}, 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "source": [
        "# Kết quả mong đợi\n",
        "sentence = \"predictable with no fun\"\n",
        "naive_bayes_predict(sentence, p_prior, p_likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFYVt0IBL_0"
      },
      "source": [
        "##2.Naive Bayes Classfier for Sentiment Analysis on Tweets\n",
        "**Phân tích cảm xúc trên tập 1Tweets1 sử dụng thuật toán phân loại Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVAHBqV7But_",
        "outputId": "daa30e9e-e3c5-4378-ae6f-c98ecbccc21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('twitter_samples')\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aC78vV6Bh_x"
      },
      "source": [
        "###2.1.Dowload Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C36MnzNxBhdE"
      },
      "outputs": [],
      "source": [
        "# Tải về tập dữ liệu tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# Chia thành 2 tập train và test\n",
        "# train: 4000 samples, test: 1000 samples\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# Tạo nhãn negative: 0, positive: 1\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMszkt7wkPGz",
        "outputId": "887e8ebf-68f8-42ea-8ad0-b1a8dda2b969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days',\n",
              " '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM',\n",
              " \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\",\n",
              " '@Impatientraider On second thought, there’s just not enough time for a DD :) But new shorts entering system. Sheep must be buying.',\n",
              " 'Jgh , but we have to go to Bayan :D bye',\n",
              " 'As an act of mischievousness, am calling the ETL layer of our in-house warehousing app Katamari.\\n\\nWell… as the name implies :p.']"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "all_positive_tweets[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIxAUu4OkUTV",
        "outputId": "2e7de849-657b-4f97-ef31-e5188b207245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hopeless for tmr :(',\n",
              " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
              " '@Hegelbon That heart sliding into the waste basket. :(',\n",
              " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
              " 'Dang starting next week I have \"work\" :(',\n",
              " \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\",\n",
              " '@RileyMcDonough make me smile :((',\n",
              " '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln',\n",
              " 'why?:(\"@tahuodyy: sialan:( https://t.co/Hv1i0xcrL2\"',\n",
              " 'Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz']"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "all_negative_tweets[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRFnS6IaCf_k"
      },
      "source": [
        "###2.2.Tiền xử lý dữ liệu cho tập `Tweets`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFezH6Udrdkx"
      },
      "source": [
        "Dựa vào việc quan sát tập dữ liệu trên chúng ta tiến hàng một số bước tiền xử lý như sau:\n",
        "- Xóa bỏ các hashtags như #FollowFriday,...\n",
        "- Xóa bỏ các thẻ gắn nhãn các tài khoản như: @Lamb2ja\n",
        "- Xóa bỏ các thẻ HTML, CSS,.. có thể có như: https://t.co/smyYriipxI\n",
        "- Xóa bỏ retweet trong text: \"RT\"\n",
        "- Xóa bỏ dấu câu và có thể xóa hết số, ký tự đặc biệt (Với mục đích tập trung ngữ nghĩa các từ)\n",
        "- Có thể thực hiện một số bước tiền xử lý khác\n",
        "- Sau khi tiền xử lý xong chúng ta tiến hành tách câu thành các từ (word base tokenizer). Ở đây chúng ta sẽ dùng bộ tách từ có sẵn cho tách từ `tweet` của nltk là `TweetTokenizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0scCMv8wCmQW"
      },
      "outputs": [],
      "source": [
        "# Ex 5\n",
        "def basic_preprocess(text):\n",
        "    '''\n",
        "    Args:\n",
        "        text: câu đầu vào\n",
        "    Output:\n",
        "        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n",
        "            được phân tách bởi khoảng trắng\n",
        "    '''\n",
        "    # xóa bỏ stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "\n",
        "    # xóa bỏ old style retweet text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "\n",
        "    # xóa bỏ hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "\n",
        "    # xóa bỏ hashtags\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # tokenize\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    text_tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    text_clean = []\n",
        "    for word in text_tokens:\n",
        "        if word not in string.punctuation:  # remove punctuation\n",
        "            text_clean.append(word)\n",
        "\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQlY1fXNDZaI",
        "outputId": "5edecf42-824c-4923-c86c-6074b70213fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'there', 'have', 'a', 'great', 'day', 'good', 'morning']"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "\n",
        "example_sentence = \"RT @Twitter @chapagain Hello There! Have a great day. #good #morning http://chapagain.com.np\"\n",
        "basic_preprocess(example_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DthCUZiZEL3d"
      },
      "source": [
        "###2.3.Huấn luyện Naive Bayes Classifier trên tập `Tweets`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFYN8KLqEQiZ",
        "outputId": "ffb88345-ef31-4cae-a5dd-b768c5034eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "4000\n",
            "V: 10841, N_pos: 41916, N_neg: 43321\n"
          ]
        }
      ],
      "source": [
        "p_prior, p_likelihood = train_naive_bayes(train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ1yd1jHEXtm",
        "outputId": "a6ad8727-6ccb-4523-b5cb-b526a20b56c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 0.5, 1: 0.5}, {0: 5.538938739337543e-05, 1: 9.477415319294123e-05})"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "#Kết quả ví dụ về xác suất tiên nghiệm và likelihood của từ happy\n",
        "p_prior, p_likelihood['boring']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4idaGXBhEz6F"
      },
      "source": [
        "###2.4.Dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vEDeak7E5Kv",
        "outputId": "11144750-a554-4cbc-fa37-1cd4fb483b51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Bro:U wan cut hair anot,ur hair long Liao bo\\nMe:since ord liao,take it easy lor treat as save $ leave it longer :)\\nBro:LOL Sibei xialan',\n",
              " 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ],
      "source": [
        "test_x[0], test_y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBBit3jiE3iU",
        "outputId": "66022cd8-280d-4c33-f292-bd2f4e82561a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prob': {0: 1.1032955242760357e-80, 1: 2.0993946427583525e-79}, 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "naive_bayes_predict(test_x[0], p_prior, p_likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt6FeZSsFxOV"
      },
      "source": [
        "###2.5.Đánh giá độ chính xác trên tập test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmihnaRYFwpD",
        "outputId": "75b5ecca-af3c-4e10-ee5c-63a72486ebae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.994\n"
          ]
        }
      ],
      "source": [
        "acc = 0\n",
        "for sentence, label in zip(test_x, test_y):\n",
        "    # predic each sentence in test set\n",
        "    pred = naive_bayes_predict(sentence, p_prior, p_likelihood)['label']\n",
        "\n",
        "    # compare predict label with target label\n",
        "    if int(pred) == int(label):\n",
        "        acc += 1\n",
        "\n",
        "print('Accuracy: ', acc/len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWIEGZ_o0NQn",
        "outputId": "9742b63d-8c72-4680-882b-ef4086c59096"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prob': {0: 7.813837845893465e-10, 1: 9.566965848216719e-10}, 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "sent = 'i very boring'\n",
        "naive_bayes_predict(sent, p_prior, p_likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQGEMKVNwlO3"
      },
      "source": [
        "##3.Logistic Regression for Sentiment Analysis on Tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3QCFT7XxI6P"
      },
      "source": [
        "###3.1.Download Dataset\n",
        "Tương tự như mục 2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yf4Qx4c9xIbz"
      },
      "outputs": [],
      "source": [
        "# Tải về tập dữ liệu tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# Chia thành 2 tập train và test\n",
        "# train: 4000 samples, test: 1000 samples\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# Tạo nhãn negative: 0, positive: 1\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFf5CnXsxcMc"
      },
      "source": [
        "###3.2. Tiền xử lý dữ liệu cho tập Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu59uxf5xYYY"
      },
      "outputs": [],
      "source": [
        "# Ex 6\n",
        "def basic_preprocess(text):\n",
        "    '''\n",
        "    Args:\n",
        "        text: câu đầu vào\n",
        "    Output:\n",
        "        text_clean: danh sách các từ (token) sau khi chuyển sang chữ thường và\n",
        "            được phân tách bởi khoảng trắng\n",
        "    '''\n",
        "    # xóa bỏ stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)\n",
        "\n",
        "    # xóa bỏ old style retweet text \"RT\"\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "\n",
        "    # xóa bỏ hyperlinks\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "\n",
        "    # xóa bỏ hashtags\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # tokenize\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    text_tokens = tokenizer.tokenize(text)\n",
        "\n",
        "    text_clean = []\n",
        "    for word in text_tokens:\n",
        "        if word not in string.punctuation:  # remove punctuation\n",
        "            text_clean.append(word)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XATJOCVxmgi",
        "outputId": "01d25ce9-206c-460b-f0aa-7a7e04ae0ace"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'there', 'have', 'a', 'great', 'day', 'good', 'morning']"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ],
      "source": [
        "# Kết quả đầu ra\n",
        "example_sentence = \"RT @Twitter @chapagain Hello There! Have a great day. #good #morning http://chapagain.com.np\"\n",
        "basic_preprocess(example_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxDEh9iAI2fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNj5wW7sxq4O"
      },
      "source": [
        "###3.3.Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h6A0zx_xvEk"
      },
      "source": [
        "####Sigmoid\n",
        "The sigmoid function: \n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2e9JGWyx0B9"
      },
      "outputs": [],
      "source": [
        "# Ex 7\n",
        "def sigmoid(z): \n",
        "    '''\n",
        "    Args:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''\n",
        "    \n",
        "    ### START CODE HERE\n",
        "    # calculate the sigmoid of z\n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlgxGHCmykTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec523dfd-66ce-4a62-e412-b45b97bc40c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "# Kết quả kiểm tra hàm sigmpoid\n",
        "sigmoid(0) == 0.5, sigmoid(4.92) == 0.9927537604041685"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k_Z1YoszL70"
      },
      "source": [
        "#### Gradient Descent Function\n",
        "* Số vòng lặp huấn luyện mô hình: `num_iters`\n",
        "* Với mỗi vòng lặp chúng ta sẽ tính `logits-z`, cost và cập nhật trọng số\n",
        "* Số samples training: `m`, số features trên mỗi sample: `n`\n",
        "* Trọng số mô hình:  \n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\ \n",
        "\\theta_2 \n",
        "\\\\ \n",
        "\\vdots\n",
        "\\\\ \n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "* Tính `logits-z`:   $$z = \\mathbf{x}\\mathbf{\\theta}$$\n",
        "    * $\\mathbf{x}$ có chiều (m, n+1) \n",
        "    * $\\mathbf{\\theta}$: có chiều (n+1, 1)\n",
        "    * $\\mathbf{z}$: có chiều (m, 1)\n",
        "* Dự đoán 'y_hat' có chiều (m,1):$$\\widehat{y}(z) = sigmoid(z)$$\n",
        "* Cost function $J$:\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\widehat{y}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-\\widehat{y}}) \\right)$$\n",
        "* Cập nhật `theta`:\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{\\widehat{y}-y} \\right) \\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIxDtGuc123A"
      },
      "outputs": [],
      "source": [
        "# Ex 8\n",
        "def gradient_descent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Args:\n",
        "        x: matrix of features, có chiều (m,n+1)\n",
        "        y: label tương ứng (m,1)\n",
        "        theta: vector trọng số (n+1,1)\n",
        "        alpha: tốc độ học\n",
        "        num_iters: số vòng lặp\n",
        "    Output:\n",
        "        J: final cost\n",
        "        theta: vector trọng số\n",
        "    '''\n",
        "\n",
        "    # lấy m số lượng các sample trong matrix x\n",
        "    loss = []\n",
        "    m = len(x)\n",
        "    \n",
        "    for i in tqdm(range(num_iters)):\n",
        "        \n",
        "        # Tính z, phép dot product: x và theta\n",
        "        z = np.dot(x, theta)\n",
        "        \n",
        "        # Tính h: sigmoid của z\n",
        "        y_hat = sigmoid(z)\n",
        "        \n",
        "        # Tính cost function\n",
        "        J = (-1 / m) * (np.dot(y.T, np.log(y_hat)) + np.dot((1 - y).T, np.log(1 - y_hat)))\n",
        "        loss.append(J[0][0])\n",
        "        # Cập nhật trọn số theta\n",
        "        theta = theta - (alpha / m) * (np.dot(x.T, (y_hat - y)))\n",
        "  \n",
        "    return J, theta, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc7xxwXQpCnI"
      },
      "outputs": [],
      "source": [
        "# print(J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhMFCHJG4K_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e334e4-5b97-4d42-b542-0a7cfbf52857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 43081.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cost 0.6664917318262262\n",
            "Weight [[5.25489588e-07]\n",
            " [4.66089993e-04]\n",
            " [3.61985668e-05]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Kiểm qua kết quả\n",
        "np.random.seed(1)\n",
        "\n",
        "# X input: 10 x 3, bias là 1\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "\n",
        "# Y label: 10 x 1\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.5).astype(float)\n",
        "\n",
        "# Apply gradient descent\n",
        "tmp_J, tmp_theta, loss = gradient_descent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 1000)\n",
        "print(f\"\\nCost {tmp_J.item()}\")\n",
        "print(f\"Weight {tmp_theta}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnnZJKKn5Unz"
      },
      "source": [
        "###3.4.Trích xuất các feature\n",
        "Chuyển từ `tweet` sang feature\n",
        "Với mỗi `tweet` sẽ được biểu diễn bởi 2 feature (Dựa vào `freq` tương tự ở mục #1 và #2):\n",
        "- số lượng các positive words\n",
        "- số lượng các negative words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLRQwL-A6kCB"
      },
      "outputs": [],
      "source": [
        "# Ex 9\n",
        "def extract_features(text, freqs):\n",
        "    '''\n",
        "    Args: \n",
        "        text: tweet\n",
        "        freqs: bộ từ điển tần suất xuất hiện của từ theo label (word, label)\n",
        "    Output: \n",
        "        x: vector feature có chiều (1,3)\n",
        "    '''\n",
        "    # tiền xử lý\n",
        "    word_l = basic_preprocess(text)\n",
        "    \n",
        "    # 3 thành phần: bias, feature 1 và feature 2\n",
        "    x = np.zeros((1, 3)) \n",
        "    \n",
        "    # bias\n",
        "    x[0,0] = 1 \n",
        "    \n",
        "    ### START CODE HERE\n",
        "    for word in word_l:\n",
        "        x[0,1] += lookup(freqs, word, 1)\n",
        "        \n",
        "        x[0,2] += lookup(freqs, word, 0)\n",
        "        \n",
        "    assert(x.shape == (1, 3))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox6yT-z_7bbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda7c003-8e14-47b2-9f12-13c79b73778a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.000e+00, 4.722e+03, 1.612e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "# Kiểm tra\n",
        "# freqs tương tự mục 1.2\n",
        "freqs = count_freq_words(train_x, train_y)\n",
        "print(train_x[0])\n",
        "extract_features(train_x[0], freqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVY_tIN58isS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94eb93c8-a658-4c24-df85-59679cc8d1c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "# Kiểm tra\n",
        "# freqs tương tự mục 1.2\n",
        "# VD: các từ không có trong bộ `freq`\n",
        "x_test = \"việt nam\"\n",
        "extract_features(x_test, freqs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oKSL2rc8xMZ"
      },
      "source": [
        "###3.5.Huấn luyện mô hình Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWoa3OEd8208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315f46a5-70f9-4059-fd4e-4a00ebcbd447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:02<00:00, 1398.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost 0.17134489822155838.\n",
            "Weight [[ 1.04365193e-07]\n",
            " [ 8.07635531e-04]\n",
            " [-6.93031654e-04]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Tạo ma trận X có kích thước mxn với n=3 (số features)\n",
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        "\n",
        "Y = np.expand_dims(train_y, 1)\n",
        "\n",
        "# Huấn luyện với số vòng lặp 1500, tốc độ học 1e-6\n",
        "J, theta, loss = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 3000)\n",
        "print(f\"Cost {J.item()}.\")\n",
        "print(f\"Weight {theta}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdP8-co6qKrw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXqe8HK8q_BB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "36a2d05b-c5eb-47ed-b868-384c20c48b0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UongNMjK9X5v"
      },
      "source": [
        "###3.6.Dự đoán\n",
        "* Tiền xử lý với dữ liệu thử nghiệm\n",
        "* Tính `logits` dựa vào công thức\n",
        "\n",
        "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVbmXR4h9b7l"
      },
      "outputs": [],
      "source": [
        "# Ex 10\n",
        "def predict_tweet(text, freqs, theta):\n",
        "    '''\n",
        "    Args: \n",
        "        text: tweet\n",
        "        freqs: bộ từ điển tần suất xuất hiện của từ theo label (word, label)\n",
        "        theta: (3,1) vector trọng số\n",
        "    Output: \n",
        "        y_pred: xác suất dự đoán\n",
        "    '''\n",
        "    \n",
        "    # extract features\n",
        "    x = extract_features(text, freqs)\n",
        "    \n",
        "    # dự đoán\n",
        "    y_pred = sigmoid(np.dot(x, theta))\n",
        "    \n",
        "    \n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImETYplt-pc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967bc1d7-7a47-4326-cce7-e4faadad2e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy -> [[0.52693969]]\n",
            "sad -> [[0.48348788]]\n"
          ]
        }
      ],
      "source": [
        "tests = [\"happy\", \"sad\"]\n",
        "for t in tests:\n",
        "    pred = predict_tweet(t, freqs, theta)\n",
        "    print(f'{t} -> {pred}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4UjFnEt_BUW"
      },
      "source": [
        "###3.7.Đánh giá độ chính xác trên tập test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg2deATX_JXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441be7cf-c4a9-4ddc-a748-511d80e01fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9705\n"
          ]
        }
      ],
      "source": [
        "acc = 0\n",
        "for sentence, label in zip(test_x, test_y):\n",
        "\n",
        "    # predic each sentence in test set\n",
        "    pred = predict_tweet(sentence, freqs, theta)\n",
        "    if pred > 0.5:\n",
        "        pred_l = 1\n",
        "    else:\n",
        "        pred_l = 0\n",
        "\n",
        "    # compare predict label with target label\n",
        "    if int(pred_l) == int(label):\n",
        "        acc += 1\n",
        "\n",
        "print('Accuracy: ', acc/len(test_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otlXS3gG6JxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71f1952-a279-406c-d2f3-b0fb4e8867ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.50664692]]\n"
          ]
        }
      ],
      "source": [
        "sentence = \"teacher is boring\"\n",
        "pred = predict_tweet(sentence, freqs, theta)\n",
        "print(pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}